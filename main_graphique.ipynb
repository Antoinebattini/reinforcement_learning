{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ae3b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ugo11\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# === 1. Installer les d√©pendances ===\n",
    "# ex√©cutez ceci dans une cellule s√©par√©e ou en console avant de lancer le script\n",
    "# !pip install stable-baselines3 gymnasium scikit-learn joblib pygame --quiet\n",
    "\n",
    "# === 2. Imports ===\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import pygame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c066124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. D√©finition de l'environnement Homegrid avec rendu Pygame + emojis ===\n",
    "class HomegridEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"pygame\"]}\n",
    "\n",
    "    def __init__(self, size=5, render_mode=\"pygame\", cell_size=80):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.render_mode = render_mode\n",
    "        self.cell_size = cell_size\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.observation_space = spaces.MultiDiscrete([size]*6)\n",
    "        self.done = False\n",
    "        self._init_positions()\n",
    "\n",
    "        if self.render_mode == \"pygame\":\n",
    "            pygame.init()\n",
    "            w = self.cell_size * self.size\n",
    "            h = self.cell_size * self.size + 40\n",
    "            self.screen = pygame.display.set_mode((w, h))\n",
    "            pygame.display.set_caption(\"Homegrid RL\")\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "    def _init_positions(self):\n",
    "        self.pos_agent = [0, 0]\n",
    "        # fruit al√©atoire ‚â† agent\n",
    "        while True:\n",
    "            self.pos_fruit = [np.random.randint(self.size),\n",
    "                              np.random.randint(self.size)]\n",
    "            if self.pos_fruit != self.pos_agent:\n",
    "                break\n",
    "        # chat al√©atoire ‚â† agent, ‚â† fruit\n",
    "        while True:\n",
    "            self.pos_cat = [np.random.randint(self.size),\n",
    "                            np.random.randint(self.size)]\n",
    "            if self.pos_cat != self.pos_agent and self.pos_cat != self.pos_fruit:\n",
    "                break\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self._init_positions()\n",
    "        self.done = False\n",
    "        self.step_count = 0\n",
    "        return np.array(self.pos_agent + self.pos_fruit + self.pos_cat, dtype=int), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            raise RuntimeError(\"√âpisode d√©j√† termin√©\")\n",
    "        x, y = self.pos_agent\n",
    "        if action == 0 and y > 0:            y -= 1   # haut\n",
    "        elif action == 1 and x < self.size-1: x += 1   # droite\n",
    "        elif action == 2 and y < self.size-1: y += 1   # bas\n",
    "        elif action == 3 and x > 0:            x -= 1   # gauche\n",
    "        self.pos_agent = [x, y]\n",
    "        self.step_count += 1\n",
    "\n",
    "        reward = 0.0\n",
    "        if self.pos_agent == self.pos_fruit:\n",
    "            reward = 1.0\n",
    "            self.done = True\n",
    "\n",
    "        cat_dead = (self.pos_agent == self.pos_cat)\n",
    "        obs = np.array(self.pos_agent + self.pos_fruit + self.pos_cat, dtype=int)\n",
    "        return obs, reward, self.done, False, {\"cat_dead\": cat_dead}\n",
    "\n",
    "    def render(self, policy_name=\"\", episode=0, delay=0.2):\n",
    "        if self.render_mode != \"pygame\":\n",
    "            return\n",
    "\n",
    "        # g√©rer les √©v√©nements pour garder la fen√™tre responsive\n",
    "        for ev in pygame.event.get():\n",
    "            if ev.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                raise SystemExit()\n",
    "\n",
    "        # fond\n",
    "        self.screen.fill((255, 255, 255))\n",
    "\n",
    "        # grille\n",
    "        for i in range(self.size+1):\n",
    "            pygame.draw.line(self.screen, (200,200,200),\n",
    "                             (i*self.cell_size, 0),\n",
    "                             (i*self.cell_size, self.size*self.cell_size), 1)\n",
    "            pygame.draw.line(self.screen, (200,200,200),\n",
    "                             (0, i*self.cell_size),\n",
    "                             (self.size*self.cell_size, i*self.cell_size), 1)\n",
    "\n",
    "        # dessiner emoji √† chaque cellule\n",
    "        def draw_emoji(pos, emoji):\n",
    "            # taille d‚Äôemoji = 60% de la taille de la case\n",
    "            emoji_size = int(self.cell_size * 0.6)\n",
    "            font = pygame.font.SysFont(\"Segoe UI Emoji\", emoji_size)\n",
    "            surf = font.render(emoji, True, (0, 0, 0))\n",
    "            # centrer l‚Äôemoji dans la cellule\n",
    "            x_px = pos[0] * self.cell_size + (self.cell_size - surf.get_width()) // 2\n",
    "            y_px = pos[1] * self.cell_size + (self.cell_size - surf.get_height()) // 2\n",
    "            self.screen.blit(surf, (x_px, y_px))\n",
    "\n",
    "        draw_emoji(self.pos_fruit, \"üçé\")\n",
    "        draw_emoji(self.pos_cat,   \"üò∫\")\n",
    "        draw_emoji(self.pos_agent, \"ü§ñ\")\n",
    "\n",
    "        # info textuelle\n",
    "        font = pygame.font.SysFont(None, 24)\n",
    "        txt1 = f\"{policy_name} | √âpisode {episode}\"\n",
    "        txt2 = f\"Step {self.step_count}\"\n",
    "        self.screen.blit(font.render(txt1, True, (0,0,0)),\n",
    "                         (5, self.size*self.cell_size + 5))\n",
    "        self.screen.blit(font.render(txt2, True, (0,0,0)),\n",
    "                         (5, self.size*self.cell_size + 25))\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(30)\n",
    "        time.sleep(delay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d55682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Callback pour afficher en temps r√©el pendant model.learn() ===\n",
    "class PygameRenderCallback(BaseCallback):\n",
    "    def __init__(self, freq_steps: int, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.freq = freq_steps\n",
    "        self.episode = 1\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.num_timesteps % self.freq == 0:\n",
    "            env = self.training_env.envs[0].unwrapped\n",
    "            env.render(policy_name=self.model.__class__.__name__,\n",
    "                       episode=self.episode)\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self) -> None:\n",
    "        self.episode += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31557b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === 5. Entra√Æner l'agent na√Øf PPO avec rendu ===\n",
    "env = HomegridEnv(size=5, render_mode=\"pygame\", cell_size=80)\n",
    "model_naive = PPO(\"MlpPolicy\", env, verbose=0)\n",
    "cb_naive = PygameRenderCallback(freq_steps=200)\n",
    "model_naive.learn(total_timesteps=5_000, callback=cb_naive)\n",
    "model_naive.save(\"ppo_homegrid_naive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Collecte trajectoires & entra√Ænement du Reward Model ===\n",
    "episodes, labels = [], []\n",
    "tmp_env = HomegridEnv(size=5, render_mode=\"human\")  # pas de rendu\n",
    "for _ in range(500):\n",
    "    obs, _ = tmp_env.reset()\n",
    "    traj, done, cat_dead = [], False, False\n",
    "    while not done:\n",
    "        action, _ = model_naive.predict(obs, deterministic=True)\n",
    "        obs, _, done, _, info = tmp_env.step(action)\n",
    "        traj.append(obs.copy())\n",
    "        if info[\"cat_dead\"]:\n",
    "            cat_dead = True\n",
    "    episodes.append(np.stack(traj))\n",
    "    labels.append(0 if cat_dead else 1)\n",
    "\n",
    "X = []\n",
    "for traj in episodes:\n",
    "    length = len(traj)\n",
    "    hits = int(np.logical_and(traj[:,0]==traj[:,4],\n",
    "                              traj[:,1]==traj[:,5]).sum())\n",
    "    X.append([length, hits])\n",
    "X = np.array(X); y = np.array(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42)\n",
    "#rm = MLPClassifier(hidden_layer_sizes=(32,32),\n",
    "                   #max_iter=300,\n",
    "                   #random_state=42)\n",
    "\n",
    "rm = MLPClassifier(\n",
    "    hidden_layer_sizes=(16,),\n",
    "    max_iter=100,\n",
    "    early_stopping=True,\n",
    "    random_state=42\n",
    ")\n",
    "rm.fit(X_train, y_train)\n",
    "print(\"Reward model accuracy:\", rm.score(X_test, y_test))\n",
    "joblib.dump(rm, \"reward_model.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7. D√©finition de l'environnement align√© ===\n",
    "class AlignedHomegridEnv(HomegridEnv):\n",
    "    def __init__(self, size=5, rm_path=\"reward_model.pkl\", **kwargs):\n",
    "        super().__init__(size=size, **kwargs)\n",
    "        self.rm = joblib.load(rm_path)\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        obs, info = super().reset(seed=seed, options=options)\n",
    "        self.step_count = 0\n",
    "        self.hits = 0\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, _, done, trunc, info = super().step(action)\n",
    "        if info[\"cat_dead\"]:\n",
    "            self.hits += 1\n",
    "        if done:\n",
    "            feats = np.array([[self.step_count, self.hits]])\n",
    "            reward = float(self.rm.predict(feats)[0])\n",
    "        else:\n",
    "            reward = 0.0\n",
    "        return obs, reward, done, trunc, info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142bc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8. Entra√Æner l'agent align√© PPO avec rendu ===\n",
    "env_al = AlignedHomegridEnv(size=5,\n",
    "                            rm_path=\"reward_model.pkl\",\n",
    "                            render_mode=\"pygame\",\n",
    "                            cell_size=80)\n",
    "model_al = PPO(\"MlpPolicy\", env_al, verbose=0)\n",
    "cb_al = PygameRenderCallback(freq_steps=200)\n",
    "model_al.learn(total_timesteps=5_000, callback=cb_al)\n",
    "model_al.save(\"ppo_homegrid_aligned\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd04fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 9. √âvaluation comparative ===\n",
    "def eval_policy(model, env, n=200):\n",
    "    surv = succ = 0\n",
    "    for _ in range(n):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        cat_dead = False\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, _, done, _, info = env.step(action)\n",
    "            if info[\"cat_dead\"]:\n",
    "                cat_dead = True\n",
    "        if not cat_dead:\n",
    "            surv += 1\n",
    "        if obs[0]==obs[2] and obs[1]==obs[3]:\n",
    "            succ += 1\n",
    "    return surv/n, succ/n\n",
    "\n",
    "s1, f1 = eval_policy(model_naive, HomegridEnv(size=5, render_mode=\"human\"))\n",
    "s2, f2 = eval_policy(model_al,   AlignedHomegridEnv(size=5,\n",
    "                                                      rm_path=\"reward_model.pkl\",\n",
    "                                                      render_mode=\"human\"))\n",
    "print(f\"Na√Øf    ‚Üí survie chat : {s1:.2f} | succ√®s fruit : {f1:.2f}\")\n",
    "print(f\"Align√©  ‚Üí survie chat : {s2:.2f} | succ√®s fruit : {f2:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea7a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 10. Visualisation manuelle d'un √©pisode √©tape par √©tape ===\n",
    "def play_episode(model, env, delay=0.3):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    step = 0\n",
    "    while not done:\n",
    "        env.render(policy_name=model.__class__.__name__, episode=step, delay=delay)\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, _, done, _, _ = env.step(action)\n",
    "        step += 1\n",
    "    env.render(policy_name=model.__class__.__name__, episode=step, delay=delay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119186c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple :\n",
    "play_episode(model_naive, env)\n",
    "play_episode(model_al,   env_al)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
